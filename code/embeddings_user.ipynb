{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from random import shuffle\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded\n",
      "                                           msno  city  bd gender  \\\n",
      "0  XQxgAYj3klVKjR3oxPPXYYFp4soD4TuBghkhMTD4oTw=     1   0          \n",
      "1  UizsfmJb9mV54qE9hCYyU07Va97c0lCRLEQX3ae+ztM=     1   0          \n",
      "2  D8nEhsIOBSoE6VthTaqDX8U6lqjJ7dLdr72mOyLya2A=     1   0          \n",
      "3  mCuD+tZ1hERA/o5GPqk38e041J8ZsBaLcu7nGoIIvhI=     1   0          \n",
      "4  q4HRBfVSssAFS9iRfxWrohxuk9kCYMKjHOEagUMV6rQ=     1   0          \n",
      "\n",
      "   registered_via  registration_year  expiration_year  \n",
      "0               7               2011             2017  \n",
      "1               7               2015             2017  \n",
      "2               4               2016             2017  \n",
      "3               9               2015             2015  \n",
      "4               4               2017             2017  \n",
      "34403\n"
     ]
    }
   ],
   "source": [
    "data_path = '/users/PAS1315/osu9187/wsdm/New_Data/'\n",
    "members = pd.read_csv(data_path + 'mem_shortlist.csv').fillna('')\n",
    "print(\"Data Loaded\")\n",
    "\n",
    "members['registration_year'] = members['registration_init_time'].apply(lambda x: int(str(x)[0:4]))\n",
    "\n",
    "members['expiration_year'] = members['expiration_date'].apply(lambda x: int(str(x)[0:4]))\n",
    "members = members.drop(['registration_init_time'], axis=1)\n",
    "members = members.drop(['expiration_date'], axis=1)\n",
    "\n",
    "print members.head()\n",
    "print len(members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the rows corresponding to a column have multiple values separated by '|'\n",
    "# character. We need to split and separate these multiple values\n",
    "\n",
    "def get_unique_entities(data, column):\n",
    "    unique = data[column].unique()\n",
    "    return unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(batch_rows, mappers):\n",
    "    batch_size = batch_rows.shape[0]\n",
    "    one_hot = [None]*batch_rows.shape[1]\n",
    "\n",
    "    for i in range(len(one_hot)):\n",
    "        one_hot[i] = np.zeros((batch_size, len(mappers[i])))\n",
    "    \n",
    "    row_num = 0\n",
    "    for (_, row) in batch_rows.iterrows():\n",
    "        for (i, element) in enumerate(row):\n",
    "            one_hot[i][row_num][mappers[i][element]] = 1\n",
    "        row_num += 1\n",
    "            \n",
    "    return (one_hot[0], one_hot[1:])\n",
    "\n",
    "def generate_mapper(data, column):\n",
    "    unique_elements = get_unique_entities(data, column)\n",
    "    mapper = dict()\n",
    "    mapper['<unk>'] = 0\n",
    "    for u in unique_elements:\n",
    "        mapper[u] = len(mapper)\n",
    "    return mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_mapper = generate_mapper(members, 'city')\n",
    "msno_mapper = generate_mapper(members, 'msno')\n",
    "reg_via_mapper = generate_mapper(members, 'registered_via')\n",
    "reg_year_mapper = generate_mapper(members, 'registration_year')\n",
    "\n",
    "mappers = [msno_mapper, city_mapper, reg_via_mapper, reg_year_mapper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(data, input_columns, target_columns, mappers, batch_size):\n",
    "    num_rows = data.shape[0]\n",
    "    num_inputs = len(input_columns)\n",
    "    num_outputs = len(target_columns)\n",
    "    all_columns = input_columns+target_columns\n",
    "    permutation = np.random.permutation(num_rows)\n",
    "    \n",
    "    while True:\n",
    "        count = 0\n",
    "        while count<=int(data.shape[0]/batch_size):\n",
    "            batch_indices = permutation[count*batch_size:min((count+1)*batch_size, num_rows)]\n",
    "            batch = data[all_columns].iloc[batch_indices]\n",
    "            count += 1\n",
    "            yield to_one_hot(batch, mappers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "input_generator = batch_generator(members, ['msno'],\n",
    "                    ['city', 'registered_via', 'registration_year'],\n",
    "                    mappers, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model compiled\n"
     ]
    }
   ],
   "source": [
    "input_col = 'msno'\n",
    "input_shape = len(mappers[0])\n",
    "output_shapes = [len(mappers[1]), len(mappers[2]), len(mappers[3])]\n",
    "num_hidden_units = 128\n",
    "hidden_activation = 'relu'\n",
    "dropout = 0.5\n",
    "batch_size = 64\n",
    "\n",
    "input_features = Input(shape = (input_shape,))\n",
    "hidden = Dropout(dropout)(\n",
    "    Dense(num_hidden_units,activation=hidden_activation)(input_features))\n",
    "output_0 = Dense(output_shapes[0], activation='softmax')(hidden)\n",
    "output_1 = Dense(output_shapes[1], activation='softmax')(hidden)\n",
    "output_2 = Dense(output_shapes[2], activation='softmax')(hidden)\n",
    "\n",
    "model = keras.models.Model(inputs = [input_features],\n",
    "                           outputs = [output_0, output_1, output_2])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(\"model compiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "537/537 [==============================] - 14s - loss: 5.5931 - dense_14_loss: 1.9102 - dense_15_loss: 1.4415 - dense_16_loss: 2.2414 - dense_14_acc: 0.5614 - dense_15_acc: 0.3181 - dense_16_acc: 0.2942    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xa0a2050>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossHistory = LossHistory()\n",
    "weights_saver = ModelCheckpoint(filepath='./model_user_embeddings/weights.{epoch:02d}.hdf5', verbose=1, period=5)\n",
    "\n",
    "model.fit_generator(input_generator, steps_per_epoch=members.shape[0]/batch_size, epochs=1, callbacks=[lossHistory, weights_saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.5930583445941489]\n"
     ]
    }
   ],
   "source": [
    "print lossHistory.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vqa",
   "language": "python",
   "name": "vqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
