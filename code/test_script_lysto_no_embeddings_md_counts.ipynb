{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, Flatten\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import cPickle as pickle\n",
    "import progressbar\n",
    "import os\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(model_file):\n",
    "    '''This method loads the song embeddings model into memory'''\n",
    "    model = keras.models.load_model(model_file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_dataset(test_file):\n",
    "    embedded_dataset = pd.read_csv(test_file).fillna('')\n",
    "    return embedded_dataset\n",
    "\n",
    "def load_songs_members_dataset():\n",
    "    songs_dataset = pd.read_csv('../../new_data/Data/songs.csv')\n",
    "    members_dataset = pd.read_csv('../Data/members.csv')\n",
    "    return songs_dataset, members_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_pickle(filename):\n",
    "    return pickle.load(open(filename, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_song_mapper_picke():\n",
    "    song_mapper = pickle.load(open('../New_Data/model_song_embeddings/song_mapper_py2.pkl', 'rb'))\n",
    "    return song_mapper\n",
    "\n",
    "def load_user_mapper_pickle():\n",
    "    user_mapper = pickle.load(open('../New_Data/model_user_embeddings/msno_mapper_py2.pkl', 'rb'))\n",
    "    return user_mapper\n",
    "\n",
    "def create_mapper(values):\n",
    "    mapper = dict()\n",
    "    for v in values:\n",
    "        mapper[v] = len(v)\n",
    "    return mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-11-6d47519b1ae7>, line 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-6d47519b1ae7>\"\u001b[0;36m, line \u001b[0;32m50\u001b[0m\n\u001b[0;31m    input_lyricist_count, input_composer_count, input_song_count_played, input_artist_count_played\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def input_generator(data):\n",
    "    num_rows = data.shape[0]\n",
    "    X_msno = np.empty(num_rows)\n",
    "    X_song_id = np.empty(num_rows)\n",
    "    X_source_system_tab = np.empty(num_rows)\n",
    "    X_source_screen_name = np.empty(num_rows)\n",
    "    X_source_type = np.empty(num_rows)\n",
    "    batch = num_rows\n",
    "    input_genre_ids_count = np.empty(batch)\n",
    "    input_artist_count = np.empty(batch)\n",
    "    input_lyricist_count = np.empty(batch)\n",
    "    \n",
    "    input_composer_count = np.empty(batch)\n",
    "    input_song_count_played = np.empty(batch)\n",
    "    input_artist_count_played = np.empty(batch)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    song_mapper = load_song_mapper_picke()\n",
    "    user_mapper = load_user_mapper_pickle()\n",
    "    source_tab_mapper = create_mapper(data.source_system_tab.unique())\n",
    "    s_scr_name_mapper = create_mapper(data.source_screen_name.unique())\n",
    "    s_type_mapper = create_mapper(data.source_type.unique())\n",
    "\n",
    "    bar = progressbar.ProgressBar()\n",
    "    print 'Generating inputs...'\n",
    "    \n",
    "    for _, row in bar(data.iterrows()):\n",
    "        curr_msno = user_mapper[row['msno']]\n",
    "        if curr_song_id not in song_mapper:\n",
    "            X_song_id[count, ] = song_mapper[data.iloc[0]['song_id']]\n",
    "        else:    \n",
    "            X_song_id[count, ] = song_mapper[row['song_id']]\n",
    "        X_msno[count,] = curr_msno\n",
    "        X_source_system_tab[count, ] = source_tab_mapper[row['source_system_tab']]\n",
    "        X_source_screen_name[count, ] = s_scr_name_mapper[row['source_screen_name']]\n",
    "        X_source_type[count, ] = s_type_mapper[row['source_type']]\n",
    "        \n",
    "        input_genre_ids_count[count, ] = row['genre_ids_count']\n",
    "        input_artist_count[count, ] = row['artist_count']\n",
    "        input_lyricist_count[count, ] = row['lyricists_count']\n",
    "        \n",
    "        input_composer_count[count, ] = row['composer_count']\n",
    "        input_song_count_played[count, ] = row['count_song_played']\n",
    "        input_artist_count_played[count, ] = row['count_artist_played']\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "    return X_msno, X_song_id, X_source_system_tab, X_source_screen_name, X_source_type, input_genre_ids_count, input_artist_count, \n",
    "            input_lyricist_count, input_composer_count, input_song_count_played, input_artist_count_played\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission_file(preds, preds_vals):\n",
    "    submission = pd.DataFrame(columns=['id', 'target', 'preds'])\n",
    "    submission['id'] = range(len(preds))\n",
    "    submission['target'] = preds\n",
    "    submission['preds'] = preds_vals\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(filename, data):\n",
    "    data.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -model MODEL -test TEST -batch_size\n",
      "                             BATCH_SIZE\n",
      "ipykernel_launcher.py: error: argument -model is required\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/PAS1315/osu9090/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Enter the model file path and test file path')\n",
    "    parser.add_argument('-model', type=str, required=True)\n",
    "    parser.add_argument('-test', type=str, required=True)\n",
    "    parser.add_argument('-batch_size', type=str, required=True)\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    print 'Loading the model'\n",
    "    trained_model = load_trained_model(args.model)\n",
    "    print trained_model.summary()\n",
    "    test_dataset = load_test_dataset(args.test)\n",
    "    songs_dataset, members_dataset = load_songs_members_dataset()\n",
    "    test_dataset = test_dataset.merge(members_dataset, on='msno', how='left')\n",
    "    \n",
    "    test_dataset = test_dataset.merge(songs_dataset, on='song_id', how='left')\n",
    "    \n",
    "    \n",
    "    def genre_id_count(x):\n",
    "        if x == 'no_genre_id':\n",
    "            return 0\n",
    "        else:\n",
    "            return x.count('|') + 1\n",
    "\n",
    "    train_dataset = test_dataset\n",
    "\n",
    "    train_dataset['genre_ids'].fillna('no_genre_id',inplace=True)\n",
    "    train_dataset['genre_ids_count'] = train_dataset['genre_ids'].apply(genre_id_count).astype(np.int32)\n",
    "    train_dataset['genre_ids_count'] = train_dataset['genre_ids_count'] / max(train_dataset['genre_ids_count'])\n",
    "\n",
    "\n",
    "# In[90]:\n",
    "\n",
    "\n",
    "    def artist_count(x):\n",
    "        if x == 'no_artist':\n",
    "            return 0\n",
    "        else:\n",
    "            return x.count('and') + x.count(',') + x.count('feat') + x.count('&')\n",
    "\n",
    "    train_dataset['artist_name'].fillna('no_artist',inplace=True)\n",
    "    train_dataset['artist_count'] = train_dataset['artist_name'].map(str).apply(artist_count).astype(np.int32)\n",
    "    train_dataset['artist_count'] = train_dataset['artist_count'] / max(train_dataset['artist_count'])\n",
    "\n",
    "\n",
    "    # In[91]:\n",
    "\n",
    "\n",
    "    def lyricist_count(x):\n",
    "        if x == 'no_lyricist':\n",
    "            return 0\n",
    "        else:\n",
    "            return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n",
    "        return sum(map(x.count, ['|', '/', '\\\\', ';']))\n",
    "\n",
    "    train_dataset['lyricist'].fillna('no_lyricist',inplace=True)\n",
    "    train_dataset['lyricists_count'] = train_dataset['lyricist'].map(str).apply(lyricist_count).astype(np.int32)\n",
    "    train_dataset['lyricists_count'] = train_dataset['lyricists_count'] / max(train_dataset['lyricists_count'])\n",
    "\n",
    "\n",
    "    # In[92]:\n",
    "\n",
    "\n",
    "    def composer_count(x):\n",
    "        if x == 'no_composer':\n",
    "            return 0\n",
    "        else:\n",
    "            return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n",
    "\n",
    "    train_dataset['composer'].fillna('no_composer',inplace=True)\n",
    "    train_dataset['composer_count'] = train_dataset['composer'].map(str).apply(composer_count).astype(np.int8)\n",
    "    train_dataset['composer_count'] = train_dataset['composer_count'] / max(train_dataset['composer_count'])\n",
    "\n",
    "\n",
    "    # In[93]:\n",
    "\n",
    "\n",
    "    # number of times a song has been played before\n",
    "    _dict_count_song_played_train = {k: v for k, v in train_dataset['song_id'].value_counts().iteritems()}\n",
    "    def count_song_played(x):\n",
    "        try:\n",
    "            return _dict_count_song_played_train[x]\n",
    "        except KeyError:\n",
    "                return 0    \n",
    "\n",
    "    train_dataset['count_song_played'] = train_dataset['song_id'].map(str).apply(count_song_played).astype(np.int64)\n",
    "    train_dataset['count_song_played'] = train_dataset['count_song_played'] / max(train_dataset['count_song_played'])\n",
    "\n",
    "\n",
    "    # In[94]:\n",
    "\n",
    "\n",
    "    # number of times an artist has been played\n",
    "    _dict_count_artist_played_train = {k: v for k, v in train_dataset['artist_name'].value_counts().iteritems()}\n",
    "    def count_artist_played(x):\n",
    "        try:\n",
    "            return _dict_count_artist_played_train[x]\n",
    "        except KeyError:\n",
    "                return 0\n",
    "\n",
    "    train_dataset['count_artist_played'] = train_dataset['artist_name'].map(str).apply(count_artist_played).astype(np.int64)\n",
    "    train_dataset['count_artist_played'] = train_dataset['count_artist_played'] / max(train_dataset['count_artist_played'])\n",
    "\n",
    "\n",
    "    # In[95]:\n",
    "\n",
    "\n",
    "    embedded_dataset = train_dataset\n",
    "    embedded_dataset = embedded_dataset.fillna('')\n",
    "    test_dataset = embedded_dataset\n",
    "\n",
    "    \n",
    "    \n",
    "    test_X_msno, test_song_id, test_source_tab, test_screen_name, test_source_type, input_genre_ids_count, input_artist_count, input_lyricist_count, input_composer_count, input_song_count_played, input_artist_count_played = input_generator(test_dataset)\n",
    "    print 'Generating predictions'\n",
    "    preds = trained_model.predict(x = [test_X_msno, test_song_id, test_source_tab, test_screen_name, test_source_type, input_genre_ids_count, input_artist_count, input_lyricist_count, input_composer_count, input_song_count_played, input_artist_count_played])\n",
    "    predictions = [1.0 if p > 0.5 else 0.0 for p in preds]\n",
    "    submission = generate_submission_file(predictions, preds)\n",
    "    write_to_csv(args.model + '_submission.csv', submission)\n",
    "    print 'Submission written to csv file'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TerminalIPythonApp] WARNING | Subcommand `ipython nbconvert` is deprecated and will be removed in future versions.\n",
      "[TerminalIPythonApp] WARNING | You likely want to use `jupyter nbconvert` in the future\n",
      "[NbConvertApp] Converting notebook test_script_lysto_no_embeddings_md_counts.ipynb to script\n",
      "[NbConvertApp] Writing 8758 bytes to test_script_lysto_no_embeddings_md_counts.py\n"
     ]
    }
   ],
   "source": [
    "!ipython nbconvert --to script test_script_lysto_no_embeddings_md_counts.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vqa",
   "language": "python",
   "name": "vqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
